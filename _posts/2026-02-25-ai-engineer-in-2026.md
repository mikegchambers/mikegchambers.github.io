---
title: "Note: AI Engineer in 2026"
date: 2026-02-25
categories: [AI]
tags: [ai, ai-engineer, agents, mcp, rag]
description: "A check-in on the definition of an AI Engineer in 2026 - from fine-tuning to agentic systems, tools, RAG, and MCP."
---

I was just pulled into a Slack thread talking about the definition of an AI Engineer. And as my thumbs flew in response I realised that it was time for a check-in on the subject.  To that end, here is verbatim what I wrote in that thread adding in links for context:

## Ref: The definition of the AI Engineer in 2026

> Let me throw in my two cents here. The contemporary definition of AI Engineer used by most people in the industry started with the [Rise of the AI Engineer](https://www.latent.space/p/ai-engineer) blogpost. That went on to be the genesis of the [AI Engineer World's Fair](https://www.ai.engineer) etc.
>
> Back when the term was coined the world was a different place. So yes, AI Engineers worked with API hosted models and also did all the [fine tuning](https://arxiv.org/abs/2106.09685) etc and working with [synthetic data](https://arxiv.org/abs/2306.11644) emerged as a thing, [model distillation](https://arxiv.org/abs/1503.02531) etc etc.  This 'beyond the use of APIs' was required as back then the models where too expensive and not aligned with various industry verticals and use cases.
>
> The world is in a different place now. While it used to be that someone like Bloomberg would fine tune a model to work with financial data (see [BloombergGPT](https://arxiv.org/abs/2303.17564)), I would hazard a guess that they don't use that anymore. Models are big enough and powerful enough and cost effective enough that they can work with [agentic systems](https://www.anthropic.com/engineering/building-effective-agents) to do pretty much whatever we need. The cost of developing tools and data sources is far far cheaper and less risky than fine tuning a model.
>
> Fine tuning is still a thing, but it's for the [Cursors](https://www.cursor.com/blog/composer) of the world who are training very large models with the bet of carrying their whole business.
>
> So an AI Engineer todayâ€¦  someone who uses models via API, understands agentic architectures, creates tools, sets up [RAG](https://arxiv.org/abs/2005.11401), knows [MCP](https://modelcontextprotocol.io), and bottom line... manipulates strings.

---

*Editor's note: I'm the AI that helped add the links to this post (Claude). On the Bloomberg point -- Mike's instinct is well-supported. [Research showed](https://arxiv.org/abs/2305.05862) that GPT-4, with zero financial training, outperformed BloombergGPT on nearly all financial benchmarks. And in late 2025, Bloomberg [integrated Anthropic's MCP protocol](https://www.waterstechnology.com/emerging-technologies/7952551/agentic-ai-comes-to-bloomberg-terminal-via-anthropic-protocol) into the Bloomberg Terminal -- building on general-purpose models rather than relying solely on their custom-trained one. The broader trend holds: the frontier moved fast enough that domain-specific pre-training lost its edge, and the AI Engineer's toolkit shifted from training models to orchestrating them.*
